# Imports necessari
import os
import requests
from bs4 import BeautifulSoup
import gradio as gr
from dotenv import load_dotenv

# Import dei client per i modelli LLM
from openai import OpenAI
import anthropic
import google.generativeai as genai

# Carica le variabili d'ambiente dal file .env
load_dotenv()

openai_api_key = os.getenv('OPENAI_API_KEY')
anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')
google_api_key = os.getenv('GOOGLE_API_KEY')

# Stampa di controllo per verificare che le chiavi siano state caricate
if openai_api_key:
    print(f"La chiave API di OpenAI esiste e inizia con: {openai_api_key[:8]}")
else:
    print("Chiave API di OpenAI non configurata.")

if anthropic_api_key:
    print(f"La chiave API di Anthropic esiste e inizia con: {anthropic_api_key[:7]}")
else:
    print("Chiave API di Anthropic non configurata.")

if google_api_key:
    print(f"La chiave API di Google esiste e inizia con: {google_api_key[:8]}")
else:
    print("Chiave API di Google non configurata.")

# Inizializzazione esplicita dei client con le rispettive chiavi API
openai_client = OpenAI(api_key=openai_api_key)
claude_client = anthropic.Anthropic(api_key=anthropic_api_key)
genai.configure(api_key=google_api_key)

# Classe per estrarre il contenuto da una pagina web
class Website:
    def __init__(self, url):
        self.url = url
        try:
            response = requests.get(url)
            response.raise_for_status()  # Solleva un errore per status code negativi (4xx o 5xx)
            soup = BeautifulSoup(response.content, 'html.parser')
            self.title = soup.title.string if soup.title else "Nessun titolo trovato"
            # Rimuove tag irrilevanti come script, stili, immagini
            for irrelevant in soup.body(["script", "style", "img", "input", "nav", "footer", "header"]):
                irrelevant.decompose()
            self.text = soup.body.get_text(separator="\n", strip=True)
        except requests.RequestException as e:
            self.title = "Errore di connessione"
            self.text = f"Impossibile accedere all'URL: {e}"

    def get_contents(self):
        return f"Titolo della pagina:\n{self.title}\n\nContenuto della pagina:\n{self.text}\n"

# Messaggio di sistema unico per tutti i modelli
system_message = """Sei un assistente specializzato nell'analizzare il contenuto della pagina web di un'azienda.
Il tuo compito è creare un breve opuscolo (brochure) informativo per potenziali clienti, investitori e nuovi dipendenti.
La risposta deve essere sempre in formato Markdown, ben strutturata e professionale."""

# --- Funzioni di Streaming per ogni modello ---

def stream_gpt(prompt):
    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": prompt}
    ]
    stream = openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        stream=True
    )
    result = ""
    for chunk in stream:
        if chunk.choices[0].delta.content:
            result += chunk.choices[0].delta.content
            yield result

def stream_claude(prompt):
    stream = claude_client.messages.stream(
        model="claude-3-haiku-20240307",
        max_tokens=2000,
        system=system_message,
        messages=[{"role": "user", "content": prompt}],
    )
    result = ""
    with stream as s:
        for text in s.text_stream:
            result += text
            yield result

def stream_gemini(prompt):
    model = genai.GenerativeModel("gemini-2.5-flash")
    stream = model.generate_content(
        [system_message, prompt],
        stream=True
    )
    result = ""
    for chunk in stream:
        try:
            # Prova ad accedere al testo del chunk
            result += chunk.text
            yield result
        except ValueError:
            # Se il chunk non ha testo (es. è il segnale di fine),
            # ignora l'errore e continua.
            pass


# --- Funzione principale per l'interfaccia Gradio ---

def stream_brochure(company_name, url, model):
    # Genera il prompt partendo dal contenuto del sito web
    website_content = Website(url).get_contents()
    prompt = f"Genera un opuscolo per l'azienda '{company_name}'. Questo è il contenuto della sua pagina web:\n\n{website_content}"

    # Seleziona la funzione di streaming in base al modello scelto
    if model == "GPT":
        yield from stream_gpt(prompt)
    elif model == "Claude":
        yield from stream_claude(prompt)
    elif model == "Gemini":
        yield from stream_gemini(prompt)
    else:
        yield "Errore: Modello non riconosciuto."

# Creazione dell'interfaccia utente con Gradio
view = gr.Interface(
    fn=stream_brochure,
    inputs=[
        gr.Textbox(label="Nome dell'Azienda"),
        gr.Textbox(label="URL della pagina web (es. https://play-sense.shop/)"),
        gr.Dropdown(["GPT", "Claude", "Gemini"], label="Seleziona un modello", value="GPT")
    ],
    outputs=[gr.Markdown(label="Opuscolo Generato:")],
    title="Generatore di Opuscoli Aziendali",
    description="Inserisci il nome di un'azienda e l'URL della sua pagina web per generare un opuscolo informativo con il modello LLM che preferisci.",
    flagging_mode="never"
)

# Avvia l'interfaccia
view.launch()
